{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import LancasterStemmer    # nltk.stem is a package that performs stemming using different classes","metadata":{"id":"0wHbj9-JU-yb","execution":{"iopub.status.busy":"2021-10-18T12:17:31.988497Z","iopub.execute_input":"2021-10-18T12:17:31.988943Z","iopub.status.idle":"2021-10-18T12:17:31.992680Z","shell.execute_reply.started":"2021-10-18T12:17:31.988908Z","shell.execute_reply":"2021-10-18T12:17:31.991971Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Stemming","metadata":{}},{"cell_type":"code","source":"# PorterStemmer uses Suffix Stripping(removing suffixes from a word) to produce stems. PorterStemmer algorithm does not follow linguistics rather a set of 05 rules for different cases that are applied\n# in phases (step by step) to generate stems. SnowballStemmers that are used to create non-English Stemmers!\n\n# The LancasterStemmer (Paice-Husk stemmer) is an iterative algorithm with rules saved externally. LancasterStemmer is simple, but heavy stemming due to iterations and over-stemming may occur. \n# Over-stemming causes the stems to be not linguistic, or they may have no meaning.","metadata":{"execution":{"iopub.status.busy":"2021-10-18T12:30:10.815302Z","iopub.execute_input":"2021-10-18T12:30:10.815826Z","iopub.status.idle":"2021-10-18T12:30:10.820429Z","shell.execute_reply.started":"2021-10-18T12:30:10.815772Z","shell.execute_reply":"2021-10-18T12:30:10.819364Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"porter = PorterStemmer()    # create an object of class PorterStemmer\nlancaster = LancasterStemmer()\n\n# proide a word to be stemmed\nprint(\"Porter Stemmer\")\nprint(porter.stem(\"cats\"))\nprint(porter.stem(\"trouble\"))\nprint(porter.stem(\"troubling\"))\nprint(porter.stem(\"troubled\"))\nprint(\"Lancaster Stemmer\")\nprint(lancaster.stem(\"cats\"))\nprint(lancaster.stem(\"trouble\"))\nprint(lancaster.stem(\"troubling\"))\nprint(lancaster.stem(\"troubled\"))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T12:18:35.772505Z","iopub.execute_input":"2021-10-18T12:18:35.773083Z","iopub.status.idle":"2021-10-18T12:18:35.783256Z","shell.execute_reply.started":"2021-10-18T12:18:35.773035Z","shell.execute_reply":"2021-10-18T12:18:35.782468Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# A list of words to be stemmed | Word vs PorterStremmer vs LancasterStemmer\nword_list = [\"friend\", \"friendship\", \"friends\", \"friendships\",\"stabil\",\"destabilize\",\"misunderstanding\",\"railroad\",\"moonlight\",\"football\"]\nprint(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Porter Stemmer\",\"lancaster Stemmer\"))\nfor word in word_list:\n    print(\"{0:20}{1:20}{2:20}\".format(word,porter.stem(word),lancaster.stem(word)))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T12:25:38.528835Z","iopub.execute_input":"2021-10-18T12:25:38.529301Z","iopub.status.idle":"2021-10-18T12:25:38.539758Z","shell.execute_reply.started":"2021-10-18T12:25:38.529269Z","shell.execute_reply":"2021-10-18T12:25:38.538605Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Stemming Sentences","metadata":{}},{"cell_type":"code","source":"sentence=\"Pythoners are very intelligent and work very pythonly and now they are pythoning their way to success.\"\nporter.stem(sentence)  # As you see the stemmer sees the entire sentence as a word, so it returns it as it is. ","metadata":{"execution":{"iopub.status.busy":"2021-10-18T12:48:02.299476Z","iopub.execute_input":"2021-10-18T12:48:02.300193Z","iopub.status.idle":"2021-10-18T12:48:02.307356Z","shell.execute_reply.started":"2021-10-18T12:48:02.300140Z","shell.execute_reply":"2021-10-18T12:48:02.306489Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# We need to stem each word in the sentence and return a combined sentence. To separate the sentence into words, you can use tokenizer. The nltk tokenizer separates the sentence into words as follows. \n# You can create a function and just pass the sentence to the function, and it will give you the stemmed sentence. \n\nfrom nltk.tokenize import sent_tokenize, word_tokenize\ndef stemSentence(sentence):\n    token_words=word_tokenize(sentence)\n    token_words\n    stem_sentence = []\n    for word in token_words:\n        stem_sentence.append(porter.stem(word))\n        stem_sentence.append(\" \")\n    return \"\".join(stem_sentence)\n\nx = stemSentence(sentence)\nprint(x)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T12:48:04.924266Z","iopub.execute_input":"2021-10-18T12:48:04.924618Z","iopub.status.idle":"2021-10-18T12:48:04.931774Z","shell.execute_reply.started":"2021-10-18T12:48:04.924586Z","shell.execute_reply":"2021-10-18T12:48:04.930710Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Python nltk provides not only two English stemmers: PorterStemmer and LancasterStemmer but also a lot of non-English stemmers as part of SnowballStemmers, ISRIStemmer, RSLPSStemmer.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lemmatization ","metadata":{"id":"LBFywag43lDC"}},{"cell_type":"code","source":"# Lemmatization reduces the inflected words properly ensuring that the root word belongs to the language. In Lemmatization root word is called Lemma.\n# A lemma (plural lemmas or lemmata) is the canonical form, dictionary form, or citation form of a set of words.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\n\nsentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\npunctuations=\"?:!.,;\"\nsentence_words = nltk.word_tokenize(sentence)\nfor word in sentence_words:\n    if word in punctuations:\n        sentence_words.remove(word)\n\nsentence_words\nprint(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\nfor word in sentence_words:\n    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))\n    \n# In the above output, you must be wondering that no actual root form has been given for any word, this is because they are given without context. You need to provide the context \n# in which you want to lemmatize that is the parts-of-speech (POS). This is done by giving the value for pos parameter in wordnet_lemmatizer.lemmatize.","metadata":{"execution":{"iopub.status.busy":"2021-10-18T12:53:03.122088Z","iopub.execute_input":"2021-10-18T12:53:03.122514Z","iopub.status.idle":"2021-10-18T12:53:05.770612Z","shell.execute_reply.started":"2021-10-18T12:53:03.122483Z","shell.execute_reply":"2021-10-18T12:53:05.769570Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for word in sentence_words:\n    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word, pos=\"v\")))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T12:56:19.308200Z","iopub.execute_input":"2021-10-18T12:56:19.308641Z","iopub.status.idle":"2021-10-18T12:56:19.316978Z","shell.execute_reply.started":"2021-10-18T12:56:19.308603Z","shell.execute_reply":"2021-10-18T12:56:19.316158Z"},"trusted":true},"execution_count":18,"outputs":[]}]}